{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPhYDZWPh+hplb1moa7ceZN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aloofzebra03/Ielektron-Internship/blob/main/Project/preparing_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqjGhB07_3r-",
        "outputId": "a44a5bc5-fc02-43a1-8889-ee5ffbbb5d9b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger\n",
        "import xml.etree.ElementTree as ET\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pickle"
      ],
      "metadata": {
        "id": "2p2onFobAwP7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_source_path = '/content/drive/MyDrive/IDD_lite/VGG_ILSVRC_16_layers_fc_reduced.h5'\n",
        "\n",
        "weights_destination_path = '/content/drive/MyDrive/IDD_lite/VGG_coco_SSD_300x300_iter_400000_subsampled_34_classes.h5'"
      ],
      "metadata": {
        "id": "ZZLmox4U9YGk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to parse XML files\n",
        "def parse_annotation(xml_file, class_map):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    boxes = []\n",
        "    labels = []\n",
        "    for obj in root.findall('object'):\n",
        "        class_name = obj.find('name').text\n",
        "        if class_name in class_map:\n",
        "            class_id = class_map[class_name]\n",
        "            bbox = obj.find('bndbox')\n",
        "            xmin = int(bbox.find('xmin').text)\n",
        "            ymin = int(bbox.find('ymin').text)\n",
        "            xmax = int(bbox.find('xmax').text)\n",
        "            ymax = int(bbox.find('ymax').text)\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "            labels.append(class_id)\n",
        "    return np.array(boxes), np.array(labels)"
      ],
      "metadata": {
        "id": "4YJnYV0pq0rT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find all JPEG and XML files in the given directory\n",
        "def find_files(directory, image_extension, annotation_extension):\n",
        "    image_files = []\n",
        "    annotation_files = []\n",
        "    for root, _, filenames in os.walk(directory):\n",
        "        for filename in filenames:\n",
        "            if filename.endswith(image_extension):\n",
        "                image_files.append(os.path.join(root, filename))\n",
        "            elif filename.endswith(annotation_extension):\n",
        "                annotation_files.append(os.path.join(root, filename))\n",
        "    return image_files, annotation_files\n"
      ],
      "metadata": {
        "id": "HbFZrK_lq1_l"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to match image files with their corresponding XML annotation files\n",
        "def match_files(image_files, annotation_files):\n",
        "    image_to_annotation = {}\n",
        "    for image_file in image_files:\n",
        "        base_name = os.path.splitext(os.path.basename(image_file))[0]\n",
        "        for annotation_file in annotation_files:\n",
        "            if os.path.splitext(os.path.basename(annotation_file))[0] == base_name:\n",
        "                image_to_annotation[image_file] = annotation_file\n",
        "                break\n",
        "    return image_to_annotation"
      ],
      "metadata": {
        "id": "6UcVAQ6rq7Mj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the paths to your dataset\n",
        "train_dirs = ['/content/drive/MyDrive/IDD_lite/train/BLR-2018-03-22_17-39-26_2_frontFar', '/content/drive/MyDrive/IDD_lite/train/BLR-2018-03-22_17-39-26_3_frontFar'\n",
        "              ,'/content/drive/MyDrive/IDD_lite/train/BLR-2018-04-16_15-24-27_frontFar','/content/drive/MyDrive/IDD_lite/train/BLR-2018-04-16_15-44-27_frontFar'\n",
        "              ,'/content/drive/MyDrive/IDD_lite/train/BLR-2018-04-16_15-54-27_frontFar','/content/drive/MyDrive/IDD_lite/train/BLR-2018-04-16_16-04-27_frontFar'\n",
        "              ,'/content/drive/MyDrive/IDD_lite/train/BLR-2018-04-16_16-14-27_frontFar']\n",
        "val_dirs = ['/content/drive/MyDrive/IDD_lite/test/BLR-2018-04-19_17-06-55_frontFar', '/content/drive/MyDrive/IDD_lite/test/BLR-2018-04-19_17-16-55_frontFar'\n",
        "              ,'/content/drive/MyDrive/IDD_lite/test/BLR-2018-04-19_17-26-55_frontFar']"
      ],
      "metadata": {
        "id": "Ew6wfloosYui"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(dirs, class_map):\n",
        "    images = []\n",
        "    boxes = []\n",
        "    labels = []\n",
        "    max_boxes = 0\n",
        "\n",
        "    for directory in dirs:\n",
        "        image_files, annotation_files = find_files(directory, '.jpg', '.xml')\n",
        "        image_to_annotation = match_files(image_files, annotation_files)\n",
        "        for image_file, annotation_file in image_to_annotation.items():\n",
        "            image = np.array(Image.open(image_file).resize((300, 300)))\n",
        "            box, label = parse_annotation(annotation_file, class_map)\n",
        "            if len(box) == 0:  # Skip images with no bounding boxes\n",
        "                continue\n",
        "            images.append(image)\n",
        "            boxes.append(box)\n",
        "            labels.append(label)\n",
        "            max_boxes = max(max_boxes, len(box))\n",
        "\n",
        "    # Pad boxes and labels\n",
        "    padded_boxes = np.zeros((len(images), max_boxes, 4))\n",
        "    padded_labels = np.zeros((len(images), max_boxes))\n",
        "\n",
        "    for i in range(len(images)):\n",
        "        padded_boxes[i, :len(boxes[i])] = boxes[i]\n",
        "        padded_labels[i, :len(labels[i])] = labels[i]\n",
        "\n",
        "    return np.array(images), padded_boxes, padded_labels"
      ],
      "metadata": {
        "id": "XWgxLcw8tc1C"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_dataset(images, boxes, labels, file_path):\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump((images, boxes, labels), f)\n",
        "\n",
        "def load_dataset_from_file(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "# Paths to save/load the datasets\n",
        "train_dataset_file = '/content/drive/MyDrive/IDD_lite/train_dataset.pkl'\n",
        "val_dataset_file = '/content/drive/MyDrive/IDD_lite/val_dataset.pkl'"
      ],
      "metadata": {
        "id": "oCuJDPVNtfTx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load or save the training dataset\n",
        "if os.path.exists(train_dataset_file):\n",
        "    train_images, train_boxes, train_labels = load_dataset_from_file(train_dataset_file)\n",
        "else:\n",
        "    train_images, train_boxes, train_labels = load_dataset(train_dirs, class_map)\n",
        "    save_dataset(train_images, train_boxes, train_labels, train_dataset_file)"
      ],
      "metadata": {
        "id": "fjmlJi6MuASG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load or save the validation dataset\n",
        "if os.path.exists(val_dataset_file):\n",
        "    val_images, val_boxes, val_labels = load_dataset_from_file(val_dataset_file)\n",
        "else:\n",
        "    val_images, val_boxes, val_labels = load_dataset(val_dirs, class_map)\n",
        "    save_dataset(val_images, val_boxes, val_labels, val_dataset_file)"
      ],
      "metadata": {
        "id": "IOXAH5aWuBVu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LCjpG856yOY5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}