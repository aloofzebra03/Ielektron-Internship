{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNNnJw8N6Pg43Y1orNXzYGu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aloofzebra03/Ielektron-Internship/blob/main/Project/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GUiJ52NDstZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff9fb7a8-2fcf-45e7-d86e-c4bbafaa179f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Reshape"
      ],
      "metadata": {
        "id": "TXC5ebU2TmtX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger"
      ],
      "metadata": {
        "id": "nru0w2zzsvM9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import xml.etree.ElementTree as ET\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "class_map = {'person': 0, 'rider': 1, 'motorcycle': 2, 'bicycle': 3, 'autorickshaw': 4, 'car': 5, 'truck': 6, 'bus': 7, 'train': 8, 'traffic light':9}\n",
        "\n",
        "# Specify the paths to your dataset\n",
        "train_dirs = ['/content/drive/MyDrive/IDD_lite/train/BLR-2018-03-22_17-39-26_2_frontFar', '/content/drive/MyDrive/IDD_lite/train/BLR-2018-03-22_17-39-26_3_frontFar'\n",
        "              ,'/content/drive/MyDrive/IDD_lite/train/BLR-2018-04-16_15-24-27_frontFar','/content/drive/MyDrive/IDD_lite/train/BLR-2018-04-16_15-44-27_frontFar'\n",
        "              ,'/content/drive/MyDrive/IDD_lite/train/BLR-2018-04-16_15-54-27_frontFar','/content/drive/MyDrive/IDD_lite/train/BLR-2018-04-16_16-04-27_frontFar'\n",
        "              ,'/content/drive/MyDrive/IDD_lite/train/BLR-2018-04-16_16-14-27_frontFar']\n",
        "val_dirs = ['/content/drive/MyDrive/IDD_lite/test/BLR-2018-04-19_17-06-55_frontFar', '/content/drive/MyDrive/IDD_lite/test/BLR-2018-04-19_17-16-55_frontFar'\n",
        "              ,'/content/drive/MyDrive/IDD_lite/test/BLR-2018-04-19_17-26-55_frontFar']\n"
      ],
      "metadata": {
        "id": "P6_Jvhzntzcp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Helper function to parse XML files\n",
        "def parse_annotation(xml_file, class_map):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    boxes = []\n",
        "    labels = []\n",
        "    for obj in root.findall('object'):\n",
        "        class_name = obj.find('name').text\n",
        "        if class_name in class_map:\n",
        "            class_id = class_map[class_name]\n",
        "            bbox = obj.find('bndbox')\n",
        "            xmin = int(bbox.find('xmin').text)\n",
        "            ymin = int(bbox.find('ymin').text)\n",
        "            xmax = int(bbox.find('xmax').text)\n",
        "            ymax = int(bbox.find('ymax').text)\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "            labels.append(class_id)\n",
        "    return np.array(boxes), np.array(labels)\n",
        "\n",
        "# Function to find all JPEG and XML files in the given directory\n",
        "def find_files(directory, image_extension, annotation_extension):\n",
        "    image_files = []\n",
        "    annotation_files = []\n",
        "    for root, _, filenames in os.walk(directory):\n",
        "        for filename in filenames:\n",
        "            if filename.endswith(image_extension):\n",
        "                image_files.append(os.path.join(root, filename))\n",
        "            elif filename.endswith(annotation_extension):\n",
        "                annotation_files.append(os.path.join(root, filename))\n",
        "    return image_files, annotation_files\n",
        "\n",
        "# Function to match image files with their corresponding XML annotation files\n",
        "def match_files(image_files, annotation_files):\n",
        "    image_to_annotation = {}\n",
        "    for image_file in image_files:\n",
        "        base_name = os.path.splitext(os.path.basename(image_file))[0]\n",
        "        for annotation_file in annotation_files:\n",
        "            if os.path.splitext(os.path.basename(annotation_file))[0] == base_name:\n",
        "                image_to_annotation[image_file] = annotation_file\n",
        "                break\n",
        "    return image_to_annotation\n",
        "\n",
        "# Function to load dataset with padding\n",
        "def load_dataset(dirs, class_map, max_boxes=20):\n",
        "    images = []\n",
        "    boxes_and_labels = []\n",
        "\n",
        "    for directory in dirs:\n",
        "        image_files, annotation_files = find_files(directory, '.jpg', '.xml')\n",
        "        image_to_annotation = match_files(image_files, annotation_files)\n",
        "        for image_file, annotation_file in image_to_annotation.items():\n",
        "            image = np.array(Image.open(image_file).resize((300, 300)))\n",
        "            box, label = parse_annotation(annotation_file, class_map)\n",
        "            if len(box) == 0:  # Skip images with no bounding boxes\n",
        "                continue\n",
        "            images.append(image)\n",
        "            padded_boxes = np.zeros((max_boxes, 4))\n",
        "            padded_labels = np.zeros(max_boxes)\n",
        "            if len(box) > 0:\n",
        "                padded_boxes[:len(box)] = box\n",
        "                padded_labels[:len(label)] = label\n",
        "            boxes_and_labels.append(np.concatenate([padded_boxes, padded_labels[:, None]], axis=-1))\n",
        "\n",
        "    return np.array(images), np.array(boxes_and_labels)\n",
        "\n",
        "def save_dataset(images, boxes_and_labels, file_path):\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump((images, boxes_and_labels), f)\n",
        "\n",
        "def load_dataset_from_file(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "# Paths to save/load the datasets\n",
        "train_dataset_file = '/content/drive/MyDrive/IDD_lite/train_dataset.pkl'\n",
        "val_dataset_file = '/content/drive/MyDrive/IDD_lite/val_dataset.pkl'\n",
        "\n",
        "# Load or save the training dataset\n",
        "if os.path.exists(train_dataset_file):\n",
        "    train_images, train_boxes_and_labels = load_dataset_from_file(train_dataset_file)\n",
        "else:\n",
        "    train_images, train_boxes_and_labels = load_dataset(train_dirs, class_map)\n",
        "    save_dataset(train_images, train_boxes_and_labels, train_dataset_file)\n",
        "\n",
        "# Load or save the validation dataset\n",
        "if os.path.exists(val_dataset_file):\n",
        "    val_images, val_boxes_and_labels = load_dataset_from_file(val_dataset_file)\n",
        "else:\n",
        "    val_images, val_boxes_and_labels = load_dataset(val_dirs, class_map)\n",
        "    save_dataset(val_images, val_boxes_and_labels, val_dataset_file)"
      ],
      "metadata": {
        "id": "0Hl3L4dQt1F0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "71a48a80-e22d-4b92-ba6c-d51cf37ce221"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not broadcast input array from shape (22,4) into shape (20,4)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1870d4f1f9ab>\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_boxes_and_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_boxes_and_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0msave_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_boxes_and_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-1870d4f1f9ab>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(dirs, class_map, max_boxes)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mpadded_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_boxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0mpadded_boxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0mpadded_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mboxes_and_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpadded_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (22,4) into shape (20,4)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained model\n",
        "pretrained_model_path = '/content/drive/MyDrive/IDD_lite/VGG_coco_SSD_300x300_iter_400000_subsampled_34_classes.h5'\n",
        "num_classes = 10  # Your custom number of classes\n",
        "input_shape = (300, 300, 3)"
      ],
      "metadata": {
        "id": "h6_9UwGOuVXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the SSD300 model\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape, include_top=False)\n",
        "x = base_model.output"
      ],
      "metadata": {
        "id": "thUdVsBTuYPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add additional SSD layers\n",
        "x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
        "x = Conv2D(num_classes + 4, (1, 1))(x)\n",
        "x = Reshape((-1, num_classes + 4))(x)"
      ],
      "metadata": {
        "id": "db7GxDemvJye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = x\n",
        "\n",
        "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Load pre-trained weights\n",
        "model.load_weights(pretrained_model_path, by_name=True, skip_mismatch=True)\n",
        "\n",
        "# Prepare the dataset\n",
        "class_map = {'person': 0, 'rider': 1, 'motorcycle': 2, 'bicycle': 3, 'autorickshaw': 4, 'car': 5, 'truck': 6, 'bus': 7, 'train': 8, 'traffic light':9}"
      ],
      "metadata": {
        "id": "s8A0LjCUvNJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom loss function for SSD\n",
        "def smooth_l1_loss(y_true, y_pred):\n",
        "    diff = tf.abs(y_true - y_pred)\n",
        "    less_than_one = tf.cast(tf.less(diff, 1.0), tf.float32)\n",
        "    loss = less_than_one * 0.5 * tf.square(diff) + (1.0 - less_than_one) * (diff - 0.5)\n",
        "    return loss\n",
        "\n",
        "def ssd_loss(y_true, y_pred):\n",
        "    y_true_bboxes = y_true[:, :, :4]\n",
        "    y_true_labels = y_true[:, :, 4]\n",
        "    y_pred_bboxes = y_pred[:, :, :4]\n",
        "    y_pred_labels = y_pred[:, :, 4:]\n",
        "\n",
        "    # Calculate the localization loss (smooth L1 loss)\n",
        "    localization_loss = smooth_l1_loss(y_true_bboxes, y_pred_bboxes)\n",
        "    localization_loss = tf.reduce_sum(localization_loss, axis=-1)  # Reduce sum over the bounding box coordinates\n",
        "\n",
        "    # Calculate the confidence loss (categorical crossentropy)\n",
        "    confidence_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true_labels, y_pred_labels)\n",
        "\n",
        "    return tf.reduce_mean(localization_loss + confidence_loss)\n",
        "\n",
        "\n",
        "# Compile the model with the correct optimizer\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss=ssd_loss)\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint = ModelCheckpoint('ssd300_finetuned.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "learning_rate_scheduler = LearningRateScheduler(schedule=lambda epoch: 0.001 * 0.1**(epoch // 10))\n",
        "terminate_on_nan = TerminateOnNaN()\n",
        "csv_logger = CSVLogger('ssd300_training_log.csv')\n",
        "\n",
        "# Train the model\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "\n",
        "history = model.fit(\n",
        "    train_images, train_boxes_and_labels,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(val_images, val_boxes_and_labels),\n",
        "    callbacks=[checkpoint, learning_rate_scheduler, terminate_on_nan, csv_logger]\n",
        ")"
      ],
      "metadata": {
        "id": "E3xG5mIJt3V8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/IDD_lite/model_trained.h5')"
      ],
      "metadata": {
        "id": "ExAit0Fzt5cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making Predictions"
      ],
      "metadata": {
        "id": "E_sHTWSlW2Mk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making Predictions"
      ],
      "metadata": {
        "id": "oWsjMeqrX9k-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "UwpifXB_YAJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_image(img_path, target_size=(300, 300)):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "RAzG8FImWYGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(model, preprocessed_image):\n",
        "    predictions = model.predict(preprocessed_image)\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "nLx32pBbXFoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_predictions(predictions, class_map, confidence_threshold=0.5):\n",
        "    bboxes = predictions[..., :4]\n",
        "    scores = predictions[..., 4:]\n",
        "\n",
        "    # Get class labels with highest score\n",
        "    class_ids = np.argmax(scores, axis=-1)\n",
        "    confidences = np.max(scores, axis=-1)\n",
        "\n",
        "    decoded_boxes = []\n",
        "    for bbox, class_id, confidence in zip(bboxes[0], class_ids[0], confidences[0]):\n",
        "        if confidence > confidence_threshold:\n",
        "            class_name = [k for k, v in class_map.items() if v == class_id][0]\n",
        "            decoded_boxes.append((class_name, confidence, bbox))\n",
        "    return decoded_boxes\n",
        "\n"
      ],
      "metadata": {
        "id": "fq1WheLhXkv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_image_path = '/content/drive/MyDrive/IDD_lite/train/BLR-2018-04-16_16-14-27_frontFar/000054_r.jpg'"
      ],
      "metadata": {
        "id": "I1vm7PI3ZbM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow  # Specific to Google Colab\n",
        "\n",
        "def draw_boxes_cv(image_path, predictions, class_map, confidence_threshold=0.5):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Image at {image_path} could not be loaded.\")\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "    image_height, image_width, _ = image.shape\n",
        "\n",
        "    # Iterate over each prediction\n",
        "    for class_name, confidence, bbox in predictions:\n",
        "        if confidence > confidence_threshold:\n",
        "            # Convert bounding boxes from normalized to pixel values if necessary\n",
        "            xmin, ymin, xmax, ymax = bbox\n",
        "            if xmax <= 1.0 and ymax <= 1.0:  # Assuming normalized coordinates\n",
        "                xmin = int(xmin * image_width)\n",
        "                ymin = int(ymin * image_height)\n",
        "                xmax = int(xmax * image_width)\n",
        "                ymax = int(ymax * image_height)\n",
        "            else:\n",
        "                xmin, ymin, xmax, ymax = int(xmin), int(ymin), int(xmax), int(ymax)\n",
        "\n",
        "            # Draw the rectangle\n",
        "            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)  # Blue color with thickness of 2\n",
        "\n",
        "            # Add label and confidence score\n",
        "            label = f'{class_name}: {confidence:.2f}'\n",
        "            label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
        "            label_ymin = max(ymin, label_size[1] + 10)\n",
        "            cv2.rectangle(image, (xmin, label_ymin - label_size[1] - 10), (xmin + label_size[0], label_ymin + 10), (255, 0, 0), cv2.FILLED)\n",
        "            cv2.putText(image, label, (xmin, label_ymin - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "\n",
        "    # Convert RGB to BGR for displaying with OpenCV\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "    cv2_imshow(image)  # Use cv2_imshow for Google Colab\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Example usage\n",
        "preprocessed_image = preprocess_image(new_image_path)\n",
        "predictions = predict_image(model, preprocessed_image)\n",
        "decoded_predictions = decode_predictions(predictions, class_map)\n",
        "draw_boxes_cv(new_image_path, decoded_predictions, class_map)\n"
      ],
      "metadata": {
        "id": "hrj-tuNDXsuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_cUL9iJqXzn2"
      },
      "execution_count": 42,
      "outputs": []
    }
  ]
}