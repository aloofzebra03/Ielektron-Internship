{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoVHVCiL94LlC7R91nZ73s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aloofzebra03/Ielektron-Internship/blob/main/Project/weights_for_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqjGhB07_3r-",
        "outputId": "16818d65-4483-4b28-a9e0-1fcf2c1df6d8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install misc_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OpNQkh_Al3P",
        "outputId": "46aa5ade-5856-4bc6-c0d1-282e49ee1736"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement misc_utils (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for misc_utils\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "def sample_tensors(weights_list, sampling_instructions, axes=None, init=None, mean=0.0, stddev=0.005):\n",
        "\n",
        "    first_tensor = weights_list[0]\n",
        "\n",
        "    if (not isinstance(sampling_instructions, (list, tuple))) or (len(sampling_instructions) != first_tensor.ndim):\n",
        "        raise ValueError(\"The sampling instructions must be a list whose length is the number of dimensions of the first tensor in `weights_list`.\")\n",
        "\n",
        "    if (not init is None) and len(init) != len(weights_list):\n",
        "        raise ValueError(\"`init` must either be `None` or a list of strings that has the same length as `weights_list`.\")\n",
        "\n",
        "    up_sample = [] # Store the dimensions along which we need to up-sample.\n",
        "    out_shape = [] # Store the shape of the output tensor here.\n",
        "    # Store two stages of the new (sub-sampled and/or up-sampled) weights tensors in the following two lists.\n",
        "    subsampled_weights_list = [] # Tensors after sub-sampling, but before up-sampling (if any).\n",
        "    upsampled_weights_list = [] # Sub-sampled tensors after up-sampling (if any), i.e. final output tensors.\n",
        "\n",
        "    # Create the slicing arrays from the sampling instructions.\n",
        "    sampling_slices = []\n",
        "    for i, sampling_inst in enumerate(sampling_instructions):\n",
        "        if isinstance(sampling_inst, (list, tuple)):\n",
        "            amax = np.amax(np.array(sampling_inst))\n",
        "            if amax >= first_tensor.shape[i]:\n",
        "                raise ValueError(\"The sample instructions for dimension {} contain index {}, which is greater than the length of that dimension.\".format(i, amax))\n",
        "            sampling_slices.append(np.array(sampling_inst))\n",
        "            out_shape.append(len(sampling_inst))\n",
        "        elif isinstance(sampling_inst, int):\n",
        "            out_shape.append(sampling_inst)\n",
        "            if sampling_inst == first_tensor.shape[i]:\n",
        "                # Nothing to sample here, we're keeping the original number of elements along this axis.\n",
        "                sampling_slice = np.arange(sampling_inst)\n",
        "                sampling_slices.append(sampling_slice)\n",
        "            elif sampling_inst < first_tensor.shape[i]:\n",
        "                # We want to SUB-sample this dimension. Randomly pick `sample_inst` many elements from it.\n",
        "                sampling_slice1 = np.array([0]) # We will always sample class 0, the background class.\n",
        "                # Sample the rest of the classes.\n",
        "                sampling_slice2 = np.sort(np.random.choice(np.arange(1, first_tensor.shape[i]), sampling_inst - 1, replace=False))\n",
        "                sampling_slice = np.concatenate([sampling_slice1, sampling_slice2])\n",
        "                sampling_slices.append(sampling_slice)\n",
        "            else:\n",
        "                # We want to UP-sample. Pick all elements from this dimension.\n",
        "                sampling_slice = np.arange(first_tensor.shape[i])\n",
        "                sampling_slices.append(sampling_slice)\n",
        "                up_sample.append(i)\n",
        "        else:\n",
        "            raise ValueError(\"Each element of the sampling instructions must be either an integer or a list/tuple of integers, but received `{}`\".format(type(sampling_inst)))\n",
        "\n",
        "    # Process the first tensor.\n",
        "    subsampled_first_tensor = np.copy(first_tensor[np.ix_(*sampling_slices)])\n",
        "    subsampled_weights_list.append(subsampled_first_tensor)\n",
        "\n",
        "    # Process the other tensors.\n",
        "    if len(weights_list) > 1:\n",
        "        for j in range(1, len(weights_list)):\n",
        "            this_sampling_slices = [sampling_slices[i] for i in axes[j-1]] # Get the sampling slices for this tensor.\n",
        "            subsampled_weights_list.append(np.copy(weights_list[j][np.ix_(*this_sampling_slices)]))\n",
        "\n",
        "    if up_sample:\n",
        "        # Take care of the dimensions that are to be up-sampled.\n",
        "\n",
        "        out_shape = np.array(out_shape)\n",
        "\n",
        "        # Process the first tensor.\n",
        "        if init is None or init[0] == 'gaussian':\n",
        "            upsampled_first_tensor = np.random.normal(loc=mean, scale=stddev, size=out_shape)\n",
        "        elif init[0] == 'zeros':\n",
        "            upsampled_first_tensor = np.zeros(out_shape)\n",
        "        else:\n",
        "            raise ValueError(\"Valid initializations are 'gaussian' and 'zeros', but received '{}'.\".format(init[0]))\n",
        "        # Pick the indices of the elements in `upsampled_first_tensor` that should be occupied by `subsampled_first_tensor`.\n",
        "        up_sample_slices = [np.arange(k) for k in subsampled_first_tensor.shape]\n",
        "        for i in up_sample:\n",
        "            # Randomly select across which indices of this dimension to scatter the elements of `new_weights_tensor` in this dimension.\n",
        "            up_sample_slice1 = np.array([0])\n",
        "            up_sample_slice2 = np.sort(np.random.choice(np.arange(1, upsampled_first_tensor.shape[i]), subsampled_first_tensor.shape[i] - 1, replace=False))\n",
        "            up_sample_slices[i] = np.concatenate([up_sample_slice1, up_sample_slice2])\n",
        "        upsampled_first_tensor[np.ix_(*up_sample_slices)] = subsampled_first_tensor\n",
        "        upsampled_weights_list.append(upsampled_first_tensor)\n",
        "\n",
        "        # Process the other tensors\n",
        "        if len(weights_list) > 1:\n",
        "            for j in range(1, len(weights_list)):\n",
        "                if init is None or init[j] == 'gaussian':\n",
        "                    upsampled_tensor = np.random.normal(loc=mean, scale=stddev, size=out_shape[axes[j-1]])\n",
        "                elif init[j] == 'zeros':\n",
        "                    upsampled_tensor = np.zeros(out_shape[axes[j-1]])\n",
        "                else:\n",
        "                    raise ValueError(\"Valid initializations are 'gaussian' and 'zeros', but received '{}'.\".format(init[j]))\n",
        "                this_up_sample_slices = [up_sample_slices[i] for i in axes[j-1]] # Get the up-sampling slices for this tensor.\n",
        "                upsampled_tensor[np.ix_(*this_up_sample_slices)] = subsampled_weights_list[j]\n",
        "                upsampled_weights_list.append(upsampled_tensor)\n",
        "\n",
        "        return upsampled_weights_list\n",
        "    else:\n",
        "        return subsampled_weights_list"
      ],
      "metadata": {
        "id": "mBljrJVnEA8o"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import shutil\n"
      ],
      "metadata": {
        "id": "2p2onFobAwP7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Set the path for the source weights file you want to load.\n",
        "\n",
        "weights_source_path = '/content/drive/MyDrive/IDD_lite/VGG_ILSVRC_16_layers_fc_reduced.h5'\n",
        "\n",
        "# TODO: Set the path and name for the destination weights file\n",
        "#       that you want to create.\n",
        "\n",
        "weights_destination_path = '/content/drive/MyDrive/IDD_lite/VGG_coco_SSD_300x300_iter_400000_subsampled_34_classes.h5'\n",
        "\n",
        "# Make a copy of the weights file.\n",
        "shutil.copy(weights_source_path, weights_destination_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2zs-ndUMAy6R",
        "outputId": "4a170173-85a6-4038-d9b3-dc3abf29b341"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/IDD_lite/VGG_coco_SSD_300x300_iter_400000_subsampled_34_classes.h5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mo7q4ZheFVw6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}